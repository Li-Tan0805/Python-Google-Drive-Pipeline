{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yagmail\n",
      "  Downloading yagmail-0.11.224-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: yagmail\n",
      "Successfully installed yagmail-0.11.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\software\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#!pip install pydrive\n",
    "#!pip install googledrivedownloader\n",
    "#!pip install yagmail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import yagmail\n",
    "\n",
    "os.chdir('C:\\\\File\\\\MCC Script - Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Functions\n",
    "\n",
    "def folder_retrieval(folder_id):\n",
    "    query = \"'\" + folder_id + \"'\" + ' in parents and trashed = false'\n",
    "    content_list = drive.ListFile({'q': query}).GetList()\n",
    "    lst = []\n",
    "    col = ['name','id','type']\n",
    "    for content in content_list:\n",
    "        lst.append([content['title'],content['id'],content['mimeType']])\n",
    "    result = pd.DataFrame(lst, columns = col)\n",
    "    return (result)\n",
    "\n",
    "def file_reader(file_name):\n",
    "    data = pd.read_excel(file_name,\n",
    "                        sheet_name = 'Plan',\n",
    "                        skiprows = 5,\n",
    "                        index_col = None)\n",
    "    try:\n",
    "        data = data[data.Geo == 'US']\n",
    "        data['Buy Details'] = file_name\n",
    "    except: \n",
    "        data = 'Empty'\n",
    "    return (data)\n",
    "\n",
    "def file_combine(file_list):\n",
    "    for i,each_file in enumerate(file_list):\n",
    "        print('Combining ' + each_file)\n",
    "        try:\n",
    "            if i == 0:\n",
    "                master = file_reader(each_file)\n",
    "                cols = master.columns\n",
    "            else:\n",
    "                temp = file_reader(each_file)\n",
    "                cols = temp.columns\n",
    "                master = pd.concat([master, temp], ignore_index=True)\n",
    "                master = master[cols]\n",
    "        except:\n",
    "            pass\n",
    "    return(master)\n",
    "\n",
    "def file_reader_cross_quarter(file_name):\n",
    "    data = pd.read_excel(file_name,\n",
    "                        sheet_name = 'Plan',\n",
    "                        skiprows = 17,\n",
    "                        index_col = None)\n",
    "    try:\n",
    "        data = data[data.Geo == 'US']\n",
    "        data['Buy Details'] = file_name\n",
    "    except: \n",
    "        data = 'Empty'\n",
    "    return (data)\n",
    "\n",
    "def file_combine_cross_quarter(file_list):\n",
    "    for i,each_file in enumerate(file_list):\n",
    "        print('Combining ' + each_file)\n",
    "        try:\n",
    "            if i == 0:\n",
    "                master = file_reader_cross_quarter(each_file)\n",
    "                cols = master.columns\n",
    "            else:\n",
    "                temp = file_reader(each_file)\n",
    "                cols = temp.columns\n",
    "                master = pd.concat([master, temp], ignore_index=True)\n",
    "                master = master[cols]\n",
    "        except:\n",
    "            pass\n",
    "    return(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=841426274923-leg1iqi48mjquh0j8h0qdgrqnsf81r4d.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "# Authentication\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear folder - Clorox\n",
    "\n",
    "os.chdir('C:\\\\File\\\\Buy Details\\\\For Python\\\\AMJ')\n",
    "files = os.listdir()\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Buy Details 15Iaop3OcnJaRsb7kvR979UczeC0R0sza\n",
      "1. Buy Details 1BbTf8ckKpZEkNlS-IajXNGiaWXayOzQP\n",
      "FY 19 Buy Details  1yaTtXUsdeke6CNBJrdZhfRkOArpILhOI\n"
     ]
    }
   ],
   "source": [
    "## Step #1. Get id based on keyword search\n",
    "    \n",
    "query = \"title contains '1. Buy Details' and mimeType = 'application/vnd.google-apps.folder'\"\n",
    "content_list = drive.ListFile({'q': query}).GetList()\n",
    "for content in content_list:\n",
    "    print(content['title'],content['id'])\n",
    "\n",
    "# id = 'xxxxxxx'\n",
    "\n",
    "## Step #2. Check what's inside the folder\n",
    "\n",
    "query = \"\" + id + \"in parents\"\n",
    "content_list = drive.ListFile({'q': query}).GetList()\n",
    "for content in content_list:\n",
    "    print(content['title'],content['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file:  Clorox Buy Details_Mar_10_NAV FY20 AMJ Natural Vitality_052620.xlsm\n",
      "Downloading file:  Clorox Buy Details_Mar_10_NEO FY20 AMJ NeoCell - GM_051220.xlsm\n",
      "Downloading file:  Clorox Buy Details_Mar_10_RBL FY20 AMJ Rainbow Light_041720.xlsm\n",
      "Downloading file:  ULF FY20 AMJ Renew Life Ultimate Flora_Mar 10_ Buy Details 5.22.20.xlsm\n",
      "Downloading file:  AKQA_Clorox_FY20_AMJ_Media Plan_Buy Details_PPH_Spore_Defense_052620.xlsm\n",
      "Downloading file:  AKQA_Clorox_FY20 AMJ_Media Plan_Buy Details_PSD VET_040720.xlsm\n",
      "Downloading file:  AKQA_Clorox_FY20 AMJ_Media Plan_Buy Details_PSD DENTAL_040720.xlsm\n",
      "Downloading file:  AKQA_Clorox_FY20 AMJ_Media Plan_Buy Details_PPH_Portfolio_040720.xlsm\n",
      "Downloading file:  AKQA_Clorox_FY20_AMJ_Media Plan_Buy Details_Operating_Suite_040720.xlsm\n",
      "Downloading file:  AKQA_Clorox_FY20_AMJ_Media Plan_Buy Details_TOT_Cleaning_040720.xlsm\n",
      "Downloading file:  AKQA_Clorox_FY20_AMJ_Media Plan_Buy Details_PCF_040720.xlsm\n",
      "Downloading file:  Newest Buy Details template_peak season_Lisa_KHP_6.08.20.xlsm\n",
      "Downloading file:  KFC HM Buy Details Kingsford SY20_CH.2_Peak Season HM_6.5.20.xlsm\n",
      "Downloading file:  Buy Details Kingsford SY20 CH.2 Peak Season KFC GM 5.26.20.xlsm\n",
      "Downloading file:  Buy Details Kingsford SY20 CH.3_KHW_5.26.20.xlsm\n",
      "Downloading file:  HHS_FY20 AMJ_Secret Sauce_Buy Details_6.5.2020.xlsm\n",
      "Downloading file:  DIP_FY20 AMJ_Ready to Eat_Buy Details_6.3.2020.xlsm\n",
      "Downloading file:  HVX_FY20 AMJ_Shaker_Buy Details_6.3.2020.xlsm\n",
      "Downloading file:  SRM_FY20 AMJ_Blasted_Buy Details_5.26.2020.xlsm\n",
      "Downloading file:  BHV_FY20 AMJ_Hidden Valley Condiments_Buy Details_4.20.2020.xlsm\n",
      "Downloading file:  GLT_Maximizer_AMJ_GM_Buy Details_Final Template_5.26.20 CR.xlsm\n",
      "Downloading file:  GTO_FY20 AMJ_Glad Trash Happy_Odor GM_Buy Details_5.26.20.xlsm\n",
      "Downloading file:  Glad Flex N Seal AMJ Buy Details_SW_5.22.20.xlsm\n",
      "Downloading file:  GPS_FY20_AMJ Glad Press N Seal Buy Details_5.22.20.xlsm\n",
      "Downloading file:  FY20 AMJ Glad Trash Odor HM Buy details_SW_5.15.20.xlsm\n",
      "Downloading file:  FSF_FY20 AMJ_Franchise-Clean Paws_Buy Details_6.5.2020.xlsm\n",
      "Downloading file:  FST_FY20 AMJ_Templeton_Buy Details_5.13.2020.xlsm\n",
      "Downloading file:  SCA_FY20 AMJ_Scoop Away_Buy Details_3.24.2020.xlsm\n",
      "Downloading file:  CDW FY20 AMJ Clorox Disinfecting Wipes GM NEW Buy Details_6.2.20.xlsm\n",
      "Downloading file:  CSP FY20 AMJ Clorox Toliet Bowl Cleaner - 5.28.20-WD.xlsm\n",
      "Downloading file:  Clorox Buy Details Scentiva CST FY20 AMJ_052820.xlsm\n",
      "Downloading file:  Clorox Buy Details LCX FY20 AMJ C2_5.27.20.xlsm\n",
      "Downloading file:  CCG FY20 AMJ Buy Details_HM_5.26.20.xlsm\n",
      "Downloading file:  CCG FY20 AMJ New Buy Details_GM_5.26.20.xlsm\n",
      "Downloading file:  PIO FY20 AMJ Pass It On_Buy Details_GM_5.25.20.xlsm\n",
      "Downloading file:  CCG FY20 AMJ Clorox Caregivers - Entre Amigas.xlsm\n",
      "Downloading file:  FabSan AMJ Buy Details _5.18.20.xlsm\n",
      "Downloading file:  PIO FY20 AMJ Pass It On_Buy Details_HM_5.7.20.xlsm\n",
      "Downloading file:  LIF FY20 AMJ Buy Details 5.22.2020.xlsm\n",
      "Downloading file:  PIN FY20 AMJ Buy Details 5.18.20.xlsm\n",
      "Downloading file:  FY20 BBT AMJ Burt's Bees Towelettes - Buy Details R1 060120.xlsm\n",
      "Downloading file:  FY20 BBM AMJ Burt's Bees Men's OOS - Buy Details R2 052720.xlsm\n",
      "Downloading file:  FY20 BBU AMJ Burt's Bees Purpose - Buy Details R4 052020.xlsm\n",
      "Downloading file:  Clorox Buy Details_Mar_20_BFC FY20 AMJ Burt's Bees Face Care_051420.xlsm\n",
      "Downloading file:  FY20 BOG AMJ Burt's On-Going (DTC) - Buy Details Original.xlsm\n",
      "Downloading file:  BFR FY20 AMJ Brita Equity - Buy Details 051920.xlsm\n",
      "Downloading file:  BNY FY20 AMJ Brita New Year New You - Buy Details 04.17.20.xlsm\n",
      "Downloading file:  Buy Details_BBD RNL RBL FY20 AMJ Prenatal Test_BD Updated.xlsm\n",
      "Downloading file:  Clorox Buy Details_PSF FY20 AMJ Pine Sol Franchise Fresh.xlsm\n",
      "Downloading file:  Buy details_KFC FY20 AMJ Kingsford Fresh.xlsm\n",
      "Downloading file:  Clorox Buy Details_HVF FY20 AMJ Fresh Amazon_v2.xlsm\n",
      "Downloading file:  Buy details_GLB FY20 AMJ Glad Flexi_4.24.20_Final.xlsm\n",
      "Downloading file:  Clorox Buy Details_FSF FY20 AMJ Fresh Step Fresh.xlsm\n",
      "Downloading file:  Buy details_FSF FY20 AMJ Advanced_Final_4.24.20.xlsm\n",
      "Downloading file:  Clorox Buy Details_CHC FY20 AMJ Clorox Homecare Franchise Fresh_Amazon_FINAL.xlsm\n",
      "Downloading file:  Burts Bees Mothers Day FY20 AMJ_6.1.20_incremental.xlsm\n",
      "Downloading file:  Clorox Buy Details_BBD FY20 AMJ Burt's Bees Fresh.xlsm\n",
      "Downloading file:  Buy details_BFG FY20 AMJ Brita Bottles_Final_4.24.20.xlsm\n",
      "Downloading file:  Buy Details_BFR fy20 AMJ Creative Messaging Test .xlsm\n",
      "Downloading file:  Clorox Buy Details_Mar_20_Renew Life Solo_FY20 AMJ_5.8.xlsm\n",
      "Downloading file:  Clorox Buy Details_Mar_20_Renew Life + VMS NYNY_AMJ_3.25.xlsm\n",
      "Downloading file:  Clorox Buy Details Template_Mar_20Renew Life + VMS Mother's Day_AMJ_3.25.xlsm\n",
      "Downloading file:  Clorox Buy Details_Mar_20_FY20 AMJ Rainbow Light Solo_5.11.xlsm\n",
      "Downloading file:  Clorox Buy Details_Mar_20_FY20 AMJ NeoCell Solo_5.18.xlsm\n",
      "Downloading file:  Clorox Buy Details_Mar_20_FY20 AMJ Natural Vitality Solo_4.21.xlsm\n",
      "Downloading file:  Buy details_BFR FY20 OND JFM_NYNY Solo_Amazon_2.14.20.xlsm\n",
      "Downloading file:  FY20_Amazon_Buy Details_JAS_OND_TBW_ODC Test_12.12.19_OND Budget cuts.xlsx\n",
      "Downloading file:  AKQA_Clorox_FY20_Media Plan_Buy Details_Renew Life + VMS NYNY_OND_1.28.xlsx\n",
      "Downloading file:  AKQA_Clorox_FY20_Media Plan_Buy Details_RNL NYNY Solo_JFM_12.20.xlsm\n",
      "Downloading file:  AKQA_Clorox_FY20_Media Plan_Buy Details_NEO Solo_JFM_2.21.xlsm\n",
      "Downloading file:  AKQA_Clorox_FY20_Media Plan_Buy Details_NAV NYNY Solo_JFM_2.19.xlsm\n",
      "Downloading file:  Buy details_MULTIASIN SNS FY20 OND JFM_AA_1.13.20.xlsm\n",
      "Downloading file:  Archive_AKQA_Clorox_FY20_Media Plan_Buy Details_BFR_RNL_CDW_GTO_SCO_BBD_Subscribe and Save_DJFM_AA_10.21.19.xlsx\n",
      "Downloading file:  Buy details_MultiASIN NYNY FY20 OND JFM_Amazon_1.13.20.xlsm\n",
      "Downloading file:  Buy details_CST FY20 JFM AMJ Scentiva Evergreen.xlsm\n",
      "Downloading file:  Buy Details GTO FY20 JFM AMJ EVERGREEN .xlsm\n",
      "Downloading file:  Buy details_GLM FY20 EVERGREEN.xlsm\n",
      "Downloading file:  Buy Details_CHC FY20 JFM AMJ EVERGREEN.xlsm\n",
      "Downloading file:  Buy details_CDW FY20 EVERGREEN.xlsm\n"
     ]
    }
   ],
   "source": [
    "# Download BD - Clorox\n",
    "\n",
    "Clorox_BD_ID = 'xxxxxxx'\n",
    "Amazon_Cross_Quarter = 'xxxxxxx'\n",
    "\n",
    "clorox_list = folder_retrieval(Clorox_BD_ID)\n",
    "AMJ_ID = clorox_list[clorox_list.name == '4. AMJ FY20'].id.to_string(index = False)\n",
    "AMJ_list = folder_retrieval(AMJ_ID)\n",
    "\n",
    "Amazon_ID = clorox_list[clorox_list.name == 'Amazon'].id.to_string(index = False)\n",
    "Amazon_list = folder_retrieval(Amazon_ID)\n",
    "Amazon_AMJ = Amazon_list[Amazon_list.name == 'AMJ'].id.to_string(index = False)\n",
    "Amazon_Cross_Quarter = Amazon_list[Amazon_list.name == 'Cross-Quarter'].id.to_string(index = False)\n",
    "Amazon_AMJ_list = folder_retrieval(Amazon_AMJ)\n",
    "Amazon_Cross_Quarter_list = folder_retrieval(Amazon_Cross_Quarter)\n",
    "\n",
    "os.chdir('C:\\\\File\\\\Buy Details\\\\For Python\\\\AMJ')\n",
    "File_Name = []\n",
    "Brand = []\n",
    "for i in range(len(AMJ_list)):\n",
    "    brand_id = AMJ_list.id.iloc[i]\n",
    "    files = folder_retrieval(brand_id)\n",
    "    if len(files)>0:\n",
    "        files = files[files.name != 'Archive']\n",
    "        files = files[files.name != 'Archived']\n",
    "        for j in range(len(files)):\n",
    "            if files.name.iloc[j] != 'Untitled spreadsheet':\n",
    "                File_Name.append(files.name.iloc[j])\n",
    "                Brand.append(AMJ_list.name.iloc[i])\n",
    "                file_id = files.id.iloc[j]\n",
    "                temp = drive.CreateFile({'id': file_id})\n",
    "                print('Downloading file:  %s' % files.name.iloc[j]) \n",
    "                temp.GetContentFile(files.name.iloc[j])\n",
    "\n",
    "for i in range(len(Amazon_AMJ_list)):\n",
    "    brand_id = Amazon_AMJ_list.id.iloc[i]\n",
    "    files = folder_retrieval(brand_id)\n",
    "    if len(files)>0:\n",
    "        files = files[files.name != 'Archive']\n",
    "        files = files[files.name != 'Archived']\n",
    "        for j in range(len(files)):\n",
    "            if files.name.iloc[j] != 'Untitled spreadsheet':\n",
    "                File_Name.append(files.name.iloc[j])\n",
    "                Brand.append('Amazon')\n",
    "                file_id = files.id.iloc[j]\n",
    "                temp = drive.CreateFile({'id': file_id})\n",
    "                print('Downloading file:  %s' % files.name.iloc[j]) \n",
    "                temp.GetContentFile(files.name.iloc[j])\n",
    "\n",
    "for i in range(len(Amazon_Cross_Quarter_list)):\n",
    "    brand_id = Amazon_Cross_Quarter_list.id[i]\n",
    "    files = folder_retrieval(brand_id)\n",
    "    if len(files)>0:\n",
    "        files = files[files.name.str.lower() != 'archive']\n",
    "        files = files[files.name.str.lower() != 'archived']\n",
    "        for j in range(len(files)):\n",
    "            if files.name.iloc[j] != 'Untitled spreadsheet':\n",
    "                if 'folder' in files.type.iloc[j]:\n",
    "                    folder_id = files.id.iloc[j]\n",
    "                    sub_files = folder_retrieval(folder_id)\n",
    "                    if len(sub_files)>0:\n",
    "                        sub_files = sub_files[sub_files.name.str.lower() != 'archive']\n",
    "                        sub_files = sub_files[sub_files.name.str.lower() != 'archived']\n",
    "                        for k in range(len(sub_files)):\n",
    "                            if sub_files.name.iloc[k] != 'Untitled spreadsheet':\n",
    "                                if 'folder' in sub_files.type.iloc[k]:\n",
    "                                    folder_id_2 = sub_files.id.iloc[k]\n",
    "                                    sub_files_2 = folder_retrieval(folder_id_2)\n",
    "                                    if len(sub_files)>0:\n",
    "                                        sub_files_2 = sub_files_2[sub_files_2.name.str.lower() != 'archive']\n",
    "                                        sub_files_2 = sub_files_2[sub_files_2.name.str.lower() != 'archived']\n",
    "                                        for l in range(len(sub_files_2)):\n",
    "                                            File_Name.append(sub_files_2.name.iloc[l])\n",
    "                                            Brand.append('Amazon Cross Quarter')\n",
    "                                            sub_file_2_id = sub_files_2.id.iloc[l]\n",
    "                                            temp = drive.CreateFile({'id': sub_file_2_id})\n",
    "                                            print('Downloading file:  %s' % sub_files_2.name.iloc[l]) \n",
    "                                            temp.GetContentFile(sub_files_2.name.iloc[l])\n",
    "                                else:\n",
    "                                    File_Name.append(sub_files.name.iloc[k])\n",
    "                                    Brand.append('Amazon Cross Quarter')\n",
    "                                    sub_file_id = sub_files.id.iloc[k]\n",
    "                                    temp = drive.CreateFile({'id': sub_file_id})\n",
    "                                    print('Downloading file:  %s' % sub_files.name.iloc[k]) \n",
    "                                    temp.GetContentFile(sub_files.name.iloc[k])\n",
    "                else:\n",
    "                    File_Name.append(files.name.iloc[j])\n",
    "                    Brand.append('Amazon Cross Quarter')\n",
    "                    file_id = files.id.iloc[j]\n",
    "                    temp = drive.CreateFile({'id': file_id})\n",
    "                    print('Downloading file:  %s' % files.name.iloc[j]) \n",
    "                    temp.GetContentFile(files.name.iloc[j])\n",
    "                    \n",
    "Reference = pd.DataFrame({'file name': File_Name, 'brand': Brand})\n",
    "Reference.to_csv('Reference.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining AKQA_Clorox_FY20 AMJ_Media Plan_Buy Details_PPH_Portfolio_040720.xlsm\n",
      "Combining AKQA_Clorox_FY20 AMJ_Media Plan_Buy Details_PSD DENTAL_040720.xlsm\n",
      "Combining AKQA_Clorox_FY20 AMJ_Media Plan_Buy Details_PSD VET_040720.xlsm\n",
      "Combining AKQA_Clorox_FY20_AMJ_Media Plan_Buy Details_Operating_Suite_040720.xlsm\n",
      "Combining AKQA_Clorox_FY20_AMJ_Media Plan_Buy Details_PCF_040720.xlsm\n",
      "Combining AKQA_Clorox_FY20_AMJ_Media Plan_Buy Details_PPH_Spore_Defense_052620.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining AKQA_Clorox_FY20_AMJ_Media Plan_Buy Details_TOT_Cleaning_040720.xlsm\n",
      "Combining AKQA_Clorox_FY20_Media Plan_Buy Details_NAV NYNY Solo_JFM_2.19.xlsm\n",
      "Combining AKQA_Clorox_FY20_Media Plan_Buy Details_NEO Solo_JFM_2.21.xlsm\n",
      "Combining AKQA_Clorox_FY20_Media Plan_Buy Details_RNL NYNY Solo_JFM_12.20.xlsm\n",
      "Combining BFR FY20 AMJ Brita Equity - Buy Details 051920.xlsm\n",
      "Combining BHV_FY20 AMJ_Hidden Valley Condiments_Buy Details_4.20.2020.xlsm\n",
      "Combining BNY FY20 AMJ Brita New Year New You - Buy Details 04.17.20.xlsm\n",
      "Combining Burts Bees Mothers Day FY20 AMJ_6.1.20_incremental.xlsm\n",
      "Combining Buy Details GTO FY20 JFM AMJ EVERGREEN .xlsm\n",
      "Combining Buy Details Kingsford SY20 CH.2 Peak Season KFC GM 5.26.20.xlsm\n",
      "Combining Buy Details Kingsford SY20 CH.3_KHW_5.26.20.xlsm\n",
      "Combining Buy Details_BBD RNL RBL FY20 AMJ Prenatal Test_BD Updated.xlsm\n",
      "Combining Buy details_BFG FY20 AMJ Brita Bottles_Final_4.24.20.xlsm\n",
      "Combining Buy Details_BFR fy20 AMJ Creative Messaging Test .xlsm\n",
      "Combining Buy details_BFR FY20 OND JFM_NYNY Solo_Amazon_2.14.20.xlsm\n",
      "Combining Buy details_CDW FY20 EVERGREEN.xlsm\n",
      "Combining Buy Details_CHC FY20 JFM AMJ EVERGREEN.xlsm\n",
      "Combining Buy details_CST FY20 JFM AMJ Scentiva Evergreen.xlsm\n",
      "Combining Buy details_FSF FY20 AMJ Advanced_Final_4.24.20.xlsm\n",
      "Combining Buy details_GLB FY20 AMJ Glad Flexi_4.24.20_Final.xlsm\n",
      "Combining Buy details_GLM FY20 EVERGREEN.xlsm\n",
      "Combining Buy details_KFC FY20 AMJ Kingsford Fresh.xlsm\n",
      "Combining Buy details_MultiASIN NYNY FY20 OND JFM_Amazon_1.13.20.xlsm\n",
      "Combining Buy details_MULTIASIN SNS FY20 OND JFM_AA_1.13.20.xlsm\n",
      "Combining CCG FY20 AMJ Buy Details_HM_5.26.20.xlsm\n",
      "Combining CCG FY20 AMJ Clorox Caregivers - Entre Amigas.xlsm\n",
      "Combining CCG FY20 AMJ New Buy Details_GM_5.26.20.xlsm\n",
      "Combining CDW FY20 AMJ Clorox Disinfecting Wipes GM NEW Buy Details_6.2.20.xlsm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1164: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining Clorox Buy Details LCX FY20 AMJ C2_5.27.20.xlsm\n",
      "Combining Clorox Buy Details Scentiva CST FY20 AMJ_052820.xlsm\n",
      "Combining Clorox Buy Details Template_Mar_20Renew Life + VMS Mother's Day_AMJ_3.25.xlsm\n",
      "Combining Clorox Buy Details_BBD FY20 AMJ Burt's Bees Fresh.xlsm\n",
      "Combining Clorox Buy Details_CHC FY20 AMJ Clorox Homecare Franchise Fresh_Amazon_FINAL.xlsm\n",
      "Combining Clorox Buy Details_FSF FY20 AMJ Fresh Step Fresh.xlsm\n",
      "Combining Clorox Buy Details_HVF FY20 AMJ Fresh Amazon_v2.xlsm\n",
      "Combining Clorox Buy Details_Mar_10_NAV FY20 AMJ Natural Vitality_052620.xlsm\n",
      "Combining Clorox Buy Details_Mar_10_NEO FY20 AMJ NeoCell - GM_051220.xlsm\n",
      "Combining Clorox Buy Details_Mar_10_RBL FY20 AMJ Rainbow Light_041720.xlsm\n",
      "Combining Clorox Buy Details_Mar_20_BFC FY20 AMJ Burt's Bees Face Care_051420.xlsm\n",
      "Combining Clorox Buy Details_Mar_20_FY20 AMJ Natural Vitality Solo_4.21.xlsm\n",
      "Combining Clorox Buy Details_Mar_20_FY20 AMJ NeoCell Solo_5.18.xlsm\n",
      "Combining Clorox Buy Details_Mar_20_FY20 AMJ Rainbow Light Solo_5.11.xlsm\n",
      "Combining Clorox Buy Details_Mar_20_Renew Life + VMS NYNY_AMJ_3.25.xlsm\n",
      "Combining Clorox Buy Details_Mar_20_Renew Life Solo_FY20 AMJ_5.8.xlsm\n",
      "Combining Clorox Buy Details_PSF FY20 AMJ Pine Sol Franchise Fresh.xlsm\n",
      "Combining CSP FY20 AMJ Clorox Toliet Bowl Cleaner - 5.28.20-WD.xlsm\n",
      "Combining DIP_FY20 AMJ_Ready to Eat_Buy Details_6.3.2020.xlsm\n",
      "Combining FabSan AMJ Buy Details _5.18.20.xlsm\n",
      "Combining FSF_FY20 AMJ_Franchise-Clean Paws_Buy Details_6.5.2020.xlsm\n",
      "Combining FST_FY20 AMJ_Templeton_Buy Details_5.13.2020.xlsm\n",
      "Combining FY20 AMJ Glad Trash Odor HM Buy details_SW_5.15.20.xlsm\n",
      "Combining FY20 BBM AMJ Burt's Bees Men's OOS - Buy Details R2 052720.xlsm\n",
      "Combining FY20 BBT AMJ Burt's Bees Towelettes - Buy Details R1 060120.xlsm\n",
      "Combining FY20 BBU AMJ Burt's Bees Purpose - Buy Details R4 052020.xlsm\n",
      "Combining FY20 BOG AMJ Burt's On-Going (DTC) - Buy Details Original.xlsm\n",
      "Combining Glad Flex N Seal AMJ Buy Details_SW_5.22.20.xlsm\n",
      "Combining GLT_Maximizer_AMJ_GM_Buy Details_Final Template_5.26.20 CR.xlsm\n",
      "Combining GPS_FY20_AMJ Glad Press N Seal Buy Details_5.22.20.xlsm\n",
      "Combining GTO_FY20 AMJ_Glad Trash Happy_Odor GM_Buy Details_5.26.20.xlsm\n",
      "Combining HHS_FY20 AMJ_Secret Sauce_Buy Details_6.5.2020.xlsm\n",
      "Combining HVX_FY20 AMJ_Shaker_Buy Details_6.3.2020.xlsm\n",
      "Combining KFC HM Buy Details Kingsford SY20_CH.2_Peak Season HM_6.5.20.xlsm\n",
      "Combining LIF FY20 AMJ Buy Details 5.22.2020.xlsm\n",
      "Combining Newest Buy Details template_peak season_Lisa_KHP_6.08.20.xlsm\n",
      "Combining PIN FY20 AMJ Buy Details 5.18.20.xlsm\n",
      "Combining PIO FY20 AMJ Pass It On_Buy Details_GM_5.25.20.xlsm\n",
      "Combining PIO FY20 AMJ Pass It On_Buy Details_HM_5.7.20.xlsm\n",
      "Combining SCA_FY20 AMJ_Scoop Away_Buy Details_3.24.2020.xlsm\n",
      "Combining SRM_FY20 AMJ_Blasted_Buy Details_5.26.2020.xlsm\n",
      "Combining ULF FY20 AMJ Renew Life Ultimate Flora_Mar 10_ Buy Details 5.22.20.xlsm\n"
     ]
    }
   ],
   "source": [
    "# Combine BD\n",
    "\n",
    "os.chdir('C:\\\\File\\\\Buy Details\\\\For Python\\\\AMJ')\n",
    "file_list = glob.glob('*.xlsm')\n",
    "master = file_combine(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get brand name and BD for further mapping\n",
    "\n",
    "reference = pd.read_csv('Reference.csv')\n",
    "reference.rename(columns={'file name':'Buy Details', 'brand':'Brand'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude empty rows and add brand info\n",
    "\n",
    "master_copy = master\n",
    "master = master[master['Geo'] != '']\n",
    "master = master.merge(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture size of the placement\n",
    "\n",
    "data = master\n",
    "Size = []\n",
    "for i in range(len(data)):\n",
    "    if data['Placement Type'][i] == 'Package':\n",
    "        Size.append('PKG')\n",
    "    elif data['Placement Type'][i] == 'PKG':\n",
    "        Size.append('PKG')\n",
    "    elif ((data['Width'][i] == 'Vast') | (data['Width'][i] == 'VAST')):\n",
    "        Size.append('0 x 0') \n",
    "    else:\n",
    "        Size.append((str(data['Width'][i]) + ' x ' + str(data['Height'][i])).split('.')[0])\n",
    "data['Size'] = Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DCM placement name\n",
    "\n",
    "columns_needed = data.loc[:,['Line Item', 'Geo','Site Name','audience + placement name','Vehicle','Cost Structure',\n",
    "                            'Campaign ID','Inventory Source','Targetin WHO','Size','Site Served or Dart']]\n",
    "data['DCM Placement Name'] = columns_needed.apply(lambda x: '|'.join(x.astype(str).values), axis=1)\n",
    "data['DCM Placement Name'].replace({'\\.0': ''}, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare diagnosis columns\n",
    "\n",
    "data['Note - Missing Campaign ID'] = ''\n",
    "data['Note - Missing Placement ID'] = ''\n",
    "data['Note - Incorrect Start Date'] = ''\n",
    "data['Note - Missing Tag Type'] = ''\n",
    "data['Note - Zero IO Rate'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag rows with missing id\n",
    "\n",
    "try:\n",
    "    data.loc[data['DCM Placement ID'].isna(), ['Note - Missing Placement ID']] = 'x'\n",
    "    data.loc[data['DCM Placement ID'].isna(), ['DCM Placement ID']] = 'Missing Placement ID'\n",
    "except:\n",
    "    print('Placment ID no problem!')\n",
    "    \n",
    "try:\n",
    "    data.loc[data['Campaign ID'].isna(), ['Note - Missing Campaign ID']] = 'x'\n",
    "    data.loc[data['Campaign ID'].isna(), ['Campaign ID']] = 'Missing Campaign ID'\n",
    "except:\n",
    "    print('Campaign ID no problem!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TBD found!\n"
     ]
    }
   ],
   "source": [
    "# Flag rows with problematic start date: missing value, TBD, start date not falling in AMJ\n",
    "\n",
    "try:\n",
    "    data.loc[data['Start Date'] == 'TBD', ['Note - Incorrect Start Date']] = 'x'\n",
    "except:\n",
    "    print('No TBD found!')\n",
    "try:\n",
    "    data.loc[data['Start Date'].isna(), ['Note - Incorrect Start Date']] = 'x'\n",
    "except:\n",
    "    print('No missing value found!')\n",
    "try:\n",
    "    data.loc[(data['Start Date'] > datetime.strptime('2020-06-29', '%Y-%m-%d')) &\n",
    "             (data['Brand'] != 'Amazon Cross Quarter'), ['Note - Incorrect Start Date']] = 'x'\n",
    "    data.loc[(data['Start Date'] < datetime.strptime('2020-03-30', '%Y-%m-%d')) &\n",
    "             (data['Brand'] != 'Amazon Cross Quarter'), ['Note - Incorrect Start Date']] = 'x'\n",
    "except:\n",
    "    print('start date all are proper!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag rows for trackable placements with no tag type\n",
    "\n",
    "data.loc[(data['Adserving Fees - Tag Type'] == '' ) & (data['Width'] != '2'), ['Note - Missing Tag Type']] = 'x'\n",
    "data.loc[(data['Adserving Fees - Tag Type'] == '' ) & (data['Width'] != '2'), ['Adserving Fees - Tag Type']] = 'Missing Tag Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag rows for non-VADD IO with zero or missing IO Rate\n",
    "\n",
    "data.loc[(data['Net/Gross Rate'].isna()) & (data['Cost Structure'].str.lower() != 'vadd') & \n",
    "         (data['Cost Structure'].str.lower() != 'flat rate - impressions') & (data['Placement Type'] == 'Package'),['Note - Zero IO Rate']] = 'x'\n",
    "data.loc[(data['Net/Gross Rate'] == 0) & (data['Cost Structure'].str.lower() != 'vadd') & \n",
    "         (data['Cost Structure'].str.lower() != 'flat rate - impressions') & (data['Placement Type'] == 'Package'),['Note - Zero IO Rate']] = 'x'\n",
    "data.loc[(data['Net/Gross Rate'].isna()) & (data['Cost Structure'].str.lower() != 'vadd') & \n",
    "         (data['Cost Structure'].str.lower() != 'flat rate - impressions') & (data['Placement Type'] == 'Package'),['Net/Gross Rate']] = 'Zero IO Rate'\n",
    "data.loc[(data['Net/Gross Rate'] == 0) & (data['Cost Structure'].str.lower() != 'vadd') & \n",
    "         (data['Cost Structure'].str.lower() != 'flat rate - impressions') & (data['Placement Type'] == 'Package'),['Net/Gross Rate']] = 'Zero IO Rate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert CPE to CPA\n",
    "\n",
    "data.loc[data['Cost Structure'] == 'CPE', 'Cost Structure'] = 'CPA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate problematic file\n",
    "\n",
    "problematic_rows = data.loc[(data['Note - Missing Campaign ID'] == 'x') | \n",
    "                            (data['Note - Missing Placement ID'] == 'x') |\n",
    "                            (data['Note - Incorrect Start Date'] == 'x') |\n",
    "                            (data['Note - Missing Tag Type'] == 'x') |\n",
    "                            (data['Note - Zero IO Rate'] == 'x')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output result\n",
    "\n",
    "os.chdir('C:\\\\File\\\\Buy Details\\\\For Python\\\\AMJ - Output')\n",
    "files = os.listdir()\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "problematic_rows.to_csv('Clorox AMJ Problematic File.csv', index = False)\n",
    "data.to_csv('Clorox AMJ BD Master File.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending Emails\n",
    "# Turn on Less Secure App Access:\n",
    "# https://myaccount.google.com/lesssecureapps\n",
    "\n",
    "yag = yagmail.SMTP('xxxxxxx', 'xxxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sending Problematic File\n",
    "\n",
    "send_to = ['someone@xx.com']\n",
    "problematic_summary = problematic_rows.loc[:,['Buy Details']]\n",
    "contents = [\n",
    "    \"Below are the BDs with problems, more info attached:\", \n",
    "    problematic_summary.drop_duplicates().to_html(),\n",
    "    \"C:\\\\File\\\\Buy Details\\\\For Python\\\\AMJ - Output\\\\Clorox AMJ Problematic File.csv\"\n",
    "]\n",
    "yag.send(send_to, 'test', contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
